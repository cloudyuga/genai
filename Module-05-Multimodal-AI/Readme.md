# ğŸ¨ Multimodal AI Labs with Gradio & Generative Models
This module showcases how to build AI-powered applications using text, images, audio, and video through Gradio, OpenAI, and multimodal embeddings. The goal is to enable learners to work with various input/output types and build end-to-end AI applications with creative user interfaces.
## ğŸ§ª Included Labs Overview

| Lab | Name                                                          | Modality           | Description                                                                 |
|-----|---------------------------------------------------------------|--------------------|-----------------------------------------------------------------------------|
| 0   | `Lab-0_Text_to_Image_Gen.ipynb`                               | ğŸ–¼ï¸ Text â†’ Image     | Generate images from text prompts using OpenAI or Stability AI APIs        |
| 1   | `Lab-1-Gradio_Birthday_Card_Generation.ipynb`                 | ğŸ“ Text            | Build a birthday card generator with themed styles and messages            |
| 2   | `Lab-2-Text-to-Video.ipynb`                                   | ğŸ¥ Text â†’ Video     | Convert story-like prompts into short videos using AI models               |
| 3   | `Lab-3-Image_Understanding.ipynb`                             | ğŸ–¼ï¸â†’ğŸ§  Image â†’ Text   | Use vision models to understand images and generate captions               |
| 4   | `Lab-4-Audio_to_Text.ipynb`                                   | ğŸ§ Audio â†’ Text     | Transcribe audio files into text using Whisper or similar models           |
| 5   | `Lab-5-Multimodal-Embeddings.ipynb`                           | ğŸ”— Text + Image     | Compare similarity between image and text using embeddings                 |
| 6   | `Lab-6-Story_and_Export_Video.ipynb`<br>`Lab-6-Story_and_video_Generator.ipynb` | ğŸ“œ Multimodal       | Generate story-driven video with narration and AI-generated visuals       |

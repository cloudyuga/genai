# ğŸ” Module-17: Securing LLM Applications

This module is dedicated to understanding and mitigating **security risks in Large Language Model (LLM)** based applications. You'll explore key vulnerabilities such as **Information Leakage** and **Prompt Injection**, and learn defensive techniques to safeguard LLM-powered systems.

---

## ğŸ§ª Included Topics

| ğŸ”¢ | Topic           | ğŸ” Focus Area            | ğŸ§¾ Description                                                                 |
|----|-----------------|--------------------------|--------------------------------------------------------------------------------|
| 1  | Information-Leak | ğŸ§  Data Leakage Risks    | Demonstrates how sensitive data (Aadhar number) can leak from LLMs if not properly sanitized or restricted. |
| 2  | Prompt-Injection | ğŸ­ Adversarial Prompts   | Shows how attackers can override system instructions and manipulate LLM responses using cleverly crafted user inputs. |

---

